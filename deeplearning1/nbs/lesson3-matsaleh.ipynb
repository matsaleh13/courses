{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a better model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GTX 1060 6GB (CNMeM is enabled with initial size: 80.0% of memory, cuDNN 5110)\n"
     ]
    }
   ],
   "source": [
    "from theano.sandbox import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "from __future__ import division, print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#path = os.path.join('input','sample')\n",
    "path = os.path.join('input','sample-10')\n",
    "#path = os.path.join('input')\n",
    "output_path = os.path.join('output','sample')\n",
    "model_path = os.path.join(output_path, 'models')\n",
    "if not os.path.exists(model_path): os.mkdir(model_path)\n",
    "\n",
    "#batch_size=64\n",
    "#batch_size=32\n",
    "#batch_size=16\n",
    "batch_size=8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Are we underfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Our validation accuracy so far has generally been higher than our training accuracy. That leads to two obvious questions:\n",
    "\n",
    "1. How is this possible?\n",
    "2. Is this desirable?\n",
    "\n",
    "The answer to (1) is that this is happening because of *dropout*. Dropout refers to a layer that randomly deletes (i.e. sets to zero) each activation in the previous layer with probability *p* (generally 0.5). This only happens during training, not when calculating the accuracy on the validation set, which is why the validation set can show higher accuracy than the training set.\n",
    "\n",
    "The purpose of dropout is to avoid overfitting. By deleting parts of the neural network at random during training, it ensures that no one part of the network can overfit to one part of the training set. The creation of dropout was one of the key developments in deep learning, and has allowed us to create rich models without overfitting. However, it can also result in underfitting if overused, and this is something we should be careful of with our model.\n",
    "\n",
    "So the answer to (2) is: this is probably not desirable. It is likely that we can get better validation set results with less (or no) dropout, if we're seeing that validation accuracy is higher than training accuracy - a strong sign of underfitting. So let's try removing dropout entirely, and see what happens!\n",
    "\n",
    "(We had dropout in this model already because the VGG authors found it necessary for the imagenet competition. But that doesn't mean it's necessary for dogs v cats, so we will do our own analysis of regularization approaches from scratch.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our high level approach here will be to start with our fine-tuned cats vs dogs model (with dropout), then fine-tune all the dense layers, after removing dropout from them. The steps we will take are:\n",
    "- Re-create and load our modified VGG model with binary dependent (i.e. dogs v cats)\n",
    "- Split the model between the convolutional (*conv*) layers and the dense layers\n",
    "- Pre-calculate the output of the conv layers, so that we don't have to redundently re-calculate them on every epoch\n",
    "- Create a new model with just the dense layers, and dropout p set to zero\n",
    "- Train this new model using the output of the conv layers as training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start with Vgg + binary output (dogs/cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before we need to start with a working model, so let's bring in our working VGG 16 model and change it to predict our binary dependent..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = vgg_ft(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "??vgg_ft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and load our fine-tuned weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.load_weights(model_path+'finetune3.h5')\n",
    "model.load_weights(os.path.join(model_path, 'finetune_1_ll.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split conv and dense layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We're going to be training a number of iterations without dropout, so it would be best for us to pre-calculate the input to the fully connected layers - i.e. the *Flatten()* layer. We'll start by finding this layer in our model, and creating a new model that contains just the layers up to and including this layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layers = model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "last_conv_idx = [index for index,layer in enumerate(layers) \n",
    "                     if type(layer) is Convolution2D][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_conv_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.convolutional.Convolution2D at 0x15c4b9c18>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers[last_conv_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_layers = layers[:last_conv_idx+1] # convolutional layers only; i.e. first N layers to the index\n",
    "conv_model = Sequential(conv_layers)\n",
    "# Dense layers - also known as fully connected or 'FC' layers\n",
    "fc_layers = layers[last_conv_idx+1:] # remaining layers are Dense/FC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate features for the FC layers by precalculating conv output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the exact same approach to creating features as we used when we created the linear model from the imagenet predictions in the last lesson - it's only the model that has changed. As you're seeing, there's a fairly small number of \"recipes\" that can get us a long way!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 499 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batches = get_batches(os.path.join(path,'train'), shuffle=False, batch_size=batch_size)\n",
    "val_batches = get_batches(os.path.join(path,'valid'), shuffle=False, batch_size=batch_size)\n",
    "\n",
    "val_classes = val_batches.classes\n",
    "trn_classes = batches.classes\n",
    "val_labels = onehot(val_classes)\n",
    "trn_labels = onehot(trn_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below:\n",
    "\n",
    "We're pre-calculating the inputs to the new model. The inputs are the training and valiation sets. So, we basically want to get the result of running those two sets thru the conv layers only and save them so we can run them through the new model.\n",
    "\n",
    "So, we use the conv-only model to run **prediction** on the training and validation sets in order to precompute the values we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_features = conv_model.predict_generator(val_batches, val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_features = conv_model.predict_generator(batches, batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(os.path.join(model_path, 'train_convlayer_features.bc'), trn_features)\n",
    "save_array(os.path.join(model_path,'valid_convlayer_features.bc'), val_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_features = load_array(os.path.join(model_path, 'train_convlayer_features.bc'))\n",
    "val_features = load_array(os.path.join(model_path,'valid_convlayer_features.bc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000L, 512L, 14L, 14L)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(499L, 512L, 14L, 14L)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove dropout from the fully-connected layer model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our new fully connected model, we'll create it using the exact same architecture as the last layers of VGG 16, so that we can conveniently copy pre-trained weights over from that model. However, we'll set the dropout layer's p values to zero, so as to effectively remove dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copy the weights from the pre-trained model.\n",
    "# NB: Since we're removing dropout, we want to half the weights\n",
    "def proc_wgts(layer): return [o/2 for o in layer.get_weights()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Such a finely tuned model needs to be updated very slowly!\n",
    "opt = RMSprop(lr=0.00001, rho=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fc_model():\n",
    "    model = Sequential([\n",
    "        MaxPooling2D(input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        Flatten(),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(0.),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(0.),\n",
    "        Dense(2, activation='softmax')\n",
    "        ])\n",
    "\n",
    "    for l1,l2 in zip(model.layers, fc_layers): l1.set_weights(proc_wgts(l2))\n",
    "\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc_model = get_fc_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the FC model to the training and validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And fit the model in the usual way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 499 samples\n",
      "Epoch 1/8\n",
      "2000/2000 [==============================] - 12s - loss: 0.0552 - acc: 0.9800 - val_loss: 0.0842 - val_acc: 0.9840\n",
      "Epoch 2/8\n",
      "2000/2000 [==============================] - 12s - loss: 0.0024 - acc: 0.9990 - val_loss: 0.0916 - val_acc: 0.9820\n",
      "Epoch 3/8\n",
      "2000/2000 [==============================] - 12s - loss: 5.3425e-05 - acc: 1.0000 - val_loss: 0.1110 - val_acc: 0.9780\n",
      "Epoch 4/8\n",
      "2000/2000 [==============================] - 12s - loss: 1.2481e-05 - acc: 1.0000 - val_loss: 0.1033 - val_acc: 0.9760\n",
      "Epoch 5/8\n",
      "2000/2000 [==============================] - 12s - loss: 5.0694e-07 - acc: 1.0000 - val_loss: 0.1294 - val_acc: 0.9820\n",
      "Epoch 6/8\n",
      "2000/2000 [==============================] - 12s - loss: 1.3894e-07 - acc: 1.0000 - val_loss: 0.1276 - val_acc: 0.9820\n",
      "Epoch 7/8\n",
      "2000/2000 [==============================] - 12s - loss: 1.2118e-07 - acc: 1.0000 - val_loss: 0.1385 - val_acc: 0.9820\n",
      "Epoch 8/8\n",
      "2000/2000 [==============================] - 12s - loss: 1.1948e-07 - acc: 1.0000 - val_loss: 0.1388 - val_acc: 0.9820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17f8cbc88>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_model.fit(trn_features, trn_labels, nb_epoch=8, \n",
    "             batch_size=batch_size, validation_data=(val_features, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the weights (no dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc_model.save_weights(os.path.join(model_path,'lesson3_no_dropout.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc_model.load_weights(os.path.join(model_path,'lesson3_no_dropout.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reducing overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've gotten the model to overfit, we can take a number of steps to reduce this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Add data augmentation to the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's try adding a small amount of data augmentation, and see if we reduce overfitting as a result. The approach will be identical to the method we used to finetune the dense layers in lesson 2, except that we will use a generator with augmentation configured. Here's how we set up the generator, and create batches from it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gen = image.ImageDataGenerator(rotation_range=15, width_shift_range=0.1, \n",
    "                               height_shift_range=0.1, zoom_range=0.1, horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 499 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batches = get_batches(os.path.join(path, 'train'), gen, batch_size=batch_size)\n",
    "# NB: We don't want to augment or shuffle the validation set\n",
    "val_batches = get_batches(os.path.join(path, 'valid'), shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the Conv and FC layers into a single model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "When using data augmentation, we can't pre-compute our convolutional layer features, since randomized changes are being made to every input image. That is, even if the training process sees the same image multiple times, each time it will have undergone different data augmentation, so the results of the convolutional layers will be different.\n",
    "\n",
    "Therefore, in order to allow data to flow through all the conv layers and our new dense layers, we attach our fully connected model to the convolutional model--after ensuring that the convolutional layers are not trainable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fc_model = get_fc_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for layer in conv_model.layers: layer.trainable = False\n",
    "# Look how easy it is to connect two models together!\n",
    "conv_model.add(fc_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now we can compile, train, and save our model as usual - note that we use *fit_generator()* since we want to pull random images from the directories on every batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile and train the combined model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "conv_model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "2000/2000 [==============================] - 51s - loss: 0.0746 - acc: 0.9725 - val_loss: 0.0721 - val_acc: 0.9840\n",
      "Epoch 2/8\n",
      "2000/2000 [==============================] - 49s - loss: 0.0375 - acc: 0.9910 - val_loss: 0.0825 - val_acc: 0.9820\n",
      "Epoch 3/8\n",
      "2000/2000 [==============================] - 49s - loss: 0.0269 - acc: 0.9920 - val_loss: 0.0997 - val_acc: 0.9800\n",
      "Epoch 4/8\n",
      "2000/2000 [==============================] - 49s - loss: 0.0133 - acc: 0.9940 - val_loss: 0.1536 - val_acc: 0.9780\n",
      "Epoch 5/8\n",
      "2000/2000 [==============================] - 49s - loss: 0.0175 - acc: 0.9965 - val_loss: 0.1053 - val_acc: 0.9800\n",
      "Epoch 6/8\n",
      "2000/2000 [==============================] - 49s - loss: 0.0140 - acc: 0.9975 - val_loss: 0.1150 - val_acc: 0.9860\n",
      "Epoch 7/8\n",
      "2000/2000 [==============================] - 49s - loss: 0.0105 - acc: 0.9970 - val_loss: 0.1363 - val_acc: 0.9840\n",
      "Epoch 8/8\n",
      "2000/2000 [==============================] - 49s - loss: 0.0093 - acc: 0.9975 - val_loss: 0.1600 - val_acc: 0.9840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15e3304e0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=8, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the weights (combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "conv_model.save_weights(os.path.join(model_path, 'aug1.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "conv_model.load_weights(os.path.join(model_path, 'aug1.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Add batchnorm to the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can use nearly the same approach as before - but this time we'll add batchnorm layers (and dropout layers):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 14, 14)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layers[-1].output_shape[1:]  # last layer shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_bn_layers(p):\n",
    "    return [\n",
    "        MaxPooling2D(input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        Flatten(),\n",
    "        Dense(4096, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(4096, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(1000, activation='softmax')\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_fc_weights_from_vgg16bn(model):\n",
    "    \"Load weights for model from the dense layers of the Vgg16BN model.\"\n",
    "    # See imagenet_batchnorm.ipynb for info on how the weights for\n",
    "    # Vgg16BN can be generated from the standard Vgg16 weights.\n",
    "    from vgg16bn import Vgg16BN\n",
    "    vgg16_bn = Vgg16BN()\n",
    "    _, fc_layers = split_at(vgg16_bn.model, Convolution2D)\n",
    "    copy_weights(fc_layers, model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "p=0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a standalone model from the BN layers of vgg16bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#bn_model = Sequential(get_bn_layers(0.6))\n",
    "bn_model = Sequential(get_bn_layers(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://files.fast.ai/models/vgg16_bn.h5\n"
     ]
    }
   ],
   "source": [
    "load_fc_weights_from_vgg16bn(bn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def proc_wgts(layer, prev_p, new_p):\n",
    "    scal = (1-prev_p)/(1-new_p)\n",
    "    return [o*scal for o in layer.get_weights()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for l in bn_model.layers: \n",
    "    if type(l)==Dense: l.set_weights(proc_wgts(l, 0.5, 0.6))  # here l == 'l' not '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Remove last layer and lock all the others\n",
    "bn_model.pop()\n",
    "for layer in bn_model.layers: layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Add linear layer (2-class) (just doing the ImageNet mapping to Kaggle dogs and cats)\n",
    "bn_model.add(Dense(2,activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bn_model.compile(Adam(), 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 499 samples\n",
      "Epoch 1/8\n",
      "2000/2000 [==============================] - 2s - loss: 0.5140 - acc: 0.8905 - val_loss: 0.1541 - val_acc: 0.9739\n",
      "Epoch 2/8\n",
      "2000/2000 [==============================] - 1s - loss: 0.1748 - acc: 0.9595 - val_loss: 0.0999 - val_acc: 0.98000.959\n",
      "Epoch 3/8\n",
      "2000/2000 [==============================] - 1s - loss: 0.2074 - acc: 0.9580 - val_loss: 0.1130 - val_acc: 0.9780\n",
      "Epoch 4/8\n",
      "2000/2000 [==============================] - 1s - loss: 0.2028 - acc: 0.9635 - val_loss: 0.0951 - val_acc: 0.9820\n",
      "Epoch 5/8\n",
      "2000/2000 [==============================] - 1s - loss: 0.1785 - acc: 0.9645 - val_loss: 0.1239 - val_acc: 0.9800\n",
      "Epoch 6/8\n",
      "2000/2000 [==============================] - 1s - loss: 0.2133 - acc: 0.9580 - val_loss: 0.1010 - val_acc: 0.9800\n",
      "Epoch 7/8\n",
      "2000/2000 [==============================] - 1s - loss: 0.1758 - acc: 0.9650 - val_loss: 0.1223 - val_acc: 0.9780\n",
      "Epoch 8/8\n",
      "2000/2000 [==============================] - 1s - loss: 0.1649 - acc: 0.9680 - val_loss: 0.1000 - val_acc: 0.9760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x176a57da0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_model.fit(trn_features, trn_labels, nb_epoch=8, validation_data=(val_features, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the weights (batchnorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bn_model.save_weights(os.path.join(model_path,'bn.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bn_model.load_weights(os.path.join(model_path,'bn.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create another BN model and combine it with the conv layers into a final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bn_layers = get_bn_layers(0.6)\n",
    "bn_layers.pop()\n",
    "bn_layers.append(Dense(2,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "final_model = Sequential(conv_layers)\n",
    "for layer in final_model.layers: layer.trainable = False\n",
    "for layer in bn_layers: final_model.add(layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the BN layers weights from the first BN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for l1,l2 in zip(bn_model.layers, bn_layers):\n",
    "    l2.set_weights(l1.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "final_model.compile(optimizer=Adam(), \n",
    "                    loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 51s - loss: 2.2081 - acc: 0.8415 - val_loss: 1.6770 - val_acc: 0.8858\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17ba69be0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=1, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the weights (final model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "final_model.save_weights(os.path.join(model_path, 'final1.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "2000/2000 [==============================] - 51s - loss: 1.8759 - acc: 0.8735 - val_loss: 1.1234 - val_acc: 0.9218\n",
      "Epoch 2/4\n",
      "2000/2000 [==============================] - 49s - loss: 1.7514 - acc: 0.8805 - val_loss: 1.0986 - val_acc: 0.9279\n",
      "Epoch 3/4\n",
      "2000/2000 [==============================] - 50s - loss: 1.6122 - acc: 0.8880 - val_loss: 0.6317 - val_acc: 0.9599\n",
      "Epoch 4/4\n",
      "2000/2000 [==============================] - 49s - loss: 1.3345 - acc: 0.9085 - val_loss: 0.5065 - val_acc: 0.9619\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18d06b860>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=4, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the weights (final model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "final_model.save_weights(os.path.join(model_path, 'final2.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "final_model.optimizer.lr=0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "2000/2000 [==============================] - 51s - loss: 1.4807 - acc: 0.8975 - val_loss: 0.4867 - val_acc: 0.9659\n",
      "Epoch 2/4\n",
      "2000/2000 [==============================] - 49s - loss: 1.4498 - acc: 0.9005 - val_loss: 0.5859 - val_acc: 0.9579\n",
      "Epoch 3/4\n",
      "2000/2000 [==============================] - 49s - loss: 1.4331 - acc: 0.9030 - val_loss: 0.7196 - val_acc: 0.9499\n",
      "Epoch 4/4\n",
      "2000/2000 [==============================] - 49s - loss: 1.3423 - acc: 0.9095 - val_loss: 0.5011 - val_acc: 0.9659\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18d057c18>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=4, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the weights (final model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bn_model.save_weights(os.path.join(model_path, 'final3.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

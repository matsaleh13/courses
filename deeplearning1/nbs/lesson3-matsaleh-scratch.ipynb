{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lesson3-matsaleh-scratch\n",
    "\n",
    "Notebook implementation of the lesson3.x.py script(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lesson3.x.py\n",
    "# Stand-alone script to run the code from the lesson2-matsaleh.ipynb Jupyter Notebook.\n",
    "\n",
    "'''\n",
    "Lesson 3 Assignment Plan:\n",
    "\n",
    "1.\tStart with Vgg16 model with binary output and weights from lesson2.5.py.\n",
    "2.\tCreate an overfitted model:\n",
    "    a. Split conv and FC layers into two separate models.\n",
    "    b. Precalculate FC layer inputs from conv layer output.\n",
    "    c. Remove dropout from the FC model.\n",
    "    d. Fit the FC model to the data.\n",
    "    e. Save the weights.\n",
    "3.\tAdd data augmentation to the training set:\n",
    "    a. Combine the Conv (locked) and FC models.\n",
    "    b. Compile and train the combined model.\n",
    "    c. Save the weights.\n",
    "4.\tAdd batchnorm to the combined model:\n",
    "    a. Create a standalone model from the Vgg16bn model's BN layers.\n",
    "    b. Fit the BN model to the data.\n",
    "    c. Save the weights.\n",
    "    d. Create another BN model and combine it with the conv model into a final model.\n",
    "    e. Set the BN layer weights from the first BN model (why not just combine *that* BN model with the conv model)?\n",
    "    f. Save the weights.\n",
    "5.\tFit the final model:\n",
    "    a. Incrementally, saving the weights along the way.\n",
    "\n",
    "lesson3.1.py:\n",
    "- Based on lesson3.0.py\n",
    "- Replacing lesson 2 models/logic with that from lesson3.ipynb\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "import click\n",
    "\n",
    "import utils\n",
    "from vgg16 import Vgg16\n",
    "\n",
    "import bcolz\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from numpy.random import random, permutation\n",
    "from scipy import misc, ndimage\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD, RMSprop, Nadam, Adam\n",
    "from keras.preprocessing import image\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Utility Functions\n",
    "#\n",
    "def onehot(x):\n",
    "    # Returns two-column matrix with one row for each class.\n",
    "    return np.array(OneHotEncoder().fit_transform(x.reshape(-1, 1)).todense())\n",
    "\n",
    "\n",
    "# Override click for sanity here\n",
    "class myClick:\n",
    "    def echo(self, msg=''):\n",
    "        print msg\n",
    "click = myClick()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Constants\n",
    "#\n",
    "INPUT_PATH = None\n",
    "OUTPUT_PATH = None\n",
    "TRAIN_PATH = None\n",
    "VALID_PATH = None\n",
    "TEST_PATH = None\n",
    "MODEL_PATH = None\n",
    "RESULTS_PATH = None\n",
    "\n",
    "BATCH_SIZE = None\n",
    "NUM_EPOCHS = None\n",
    "\n",
    "TRAIN_BATCHES = None\n",
    "TRAIN_ARRAY = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setup_folders():\n",
    "    click.echo()\n",
    "    click.echo('Setting up folders...')\n",
    "    click.echo()\n",
    "\n",
    "    click.echo('Input folder: %s' % INPUT_PATH)\n",
    "\n",
    "    global TRAIN_PATH\n",
    "    TRAIN_PATH = os.path.join(INPUT_PATH, 'train')\n",
    "    click.echo('Training data: %s' % TRAIN_PATH)\n",
    "\n",
    "    global VALID_PATH\n",
    "    VALID_PATH = os.path.join(INPUT_PATH, 'valid')\n",
    "    click.echo('Validation data: %s' % VALID_PATH)\n",
    "\n",
    "    global TEST_PATH\n",
    "    TEST_PATH = os.path.join(INPUT_PATH, 'test')\n",
    "    click.echo('Test data: %s' % TEST_PATH)\n",
    "    click.echo()\n",
    "\n",
    "    click.echo('Output folder: %s' % OUTPUT_PATH)\n",
    "\n",
    "    global MODEL_PATH\n",
    "    MODEL_PATH = os.path.join(OUTPUT_PATH, 'models')\n",
    "    if not os.path.exists(MODEL_PATH): os.makedirs(MODEL_PATH)\n",
    "    click.echo('Model data: %s' % MODEL_PATH)\n",
    "\n",
    "    global RESULTS_PATH\n",
    "    RESULTS_PATH = os.path.join(OUTPUT_PATH, 'results')\n",
    "    if not os.path.exists(RESULTS_PATH): os.makedirs(RESULTS_PATH)\n",
    "    click.echo('Results: %s' % RESULTS_PATH)\n",
    "    click.echo()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    #\n",
    "    # NOTE: Loading and use of data structures is pretty fucked up here.\n",
    "    # Some things require getting data from generators, others require NumPy arrays.\n",
    "    # In the end we use both, and sometimes re-load the data from disk and/or re-transform\n",
    "    # it more than once.\n",
    "    #\n",
    "    click.echo('Loading raw training data from %s...' % TRAIN_PATH)\n",
    "    TRAIN_BATCHES = utils.get_batches(TRAIN_PATH, shuffle=False, batch_size=BATCH_SIZE)\n",
    "\n",
    "    click.echo('Loading array from generator...')\n",
    "    TRAIN_ARRAY = utils.get_data(TRAIN_PATH)\n",
    "    click.echo('\\tshape: %s' % (TRAIN_ARRAY.shape,))\n",
    "    click.echo()\n",
    "\n",
    "    # TRAIN_DATA = os.path.join(MODEL_PATH, 'train_data.bc')\n",
    "    # click.echo('Saving processed training data to %s...' % TRAIN_DATA)\n",
    "    # utils.save_array(TRAIN_DATA, TRAIN_ARRAY)\n",
    "\n",
    "    click.echo('Loading raw validation data from %s...' % VALID_PATH)\n",
    "    VALID_BATCHES = utils.get_batches(VALID_PATH, shuffle=False, batch_size=BATCH_SIZE)\n",
    "\n",
    "    click.echo('Loading array from generator...')\n",
    "    VALID_ARRAY = utils.get_data(VALID_PATH)\n",
    "    click.echo('\\tshape: %s' % (VALID_ARRAY.shape,))\n",
    "    click.echo()\n",
    "\n",
    "    return TRAIN_BATCHES, VALID_BATCHES, TRAIN_ARRAY, VALID_ARRAY\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_true_labels(train_batches, valid_batches):\n",
    "    click.echo('Getting the true labels for every image...')\n",
    "\n",
    "    train_classes = train_batches.classes\n",
    "    train_labels = onehot(train_classes)\n",
    "    # click.echo('\\ttraining labels look like this: \\n%s\\n...\\n%s' % (train_labels[:5], train_labels[-5:]))\n",
    "    # click.echo()\n",
    "\n",
    "    valid_classes = valid_batches.classes\n",
    "    valid_labels = onehot(valid_classes)\n",
    "    # click.echo('\\tvalidation labels look like this: \\n%s\\n...\\n%s' % (valid_labels[:5], valid_labels[-5:]))\n",
    "    # click.echo()\n",
    "\n",
    "    return train_classes, valid_classes, train_labels, valid_labels\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def prepare_generators():\n",
    "#     click.echo('Preparing image data generators...')\n",
    "#     gen = image.ImageDataGenerator()\n",
    "#     # NOTE: Why do we overwrite these generators using the arrays?\n",
    "#     # TRAIN_BATCHES and VALID_BATCHES here are generators,\n",
    "#     # but still not quite the same as above.\n",
    "#     global TRAIN_BATCHES\n",
    "#     TRAIN_BATCHES = gen.flow(TRAIN_ARRAY, TRAIN_LABELS,\n",
    "#                             batch_size=BATCH_SIZE, shuffle=True)\n",
    "#     global VALID_BATCHES\n",
    "#     VALID_BATCHES = gen.flow(VALID_ARRAY, VALID_LABELS,\n",
    "#                             batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(opt):\n",
    "    '''\n",
    "    Create a replica of the model in the state as of the end of Lesson 2.\n",
    "    That is, we had replaced the existing final Dense layer of 1000 outputs with a\n",
    "    linear (softmax) one having 2 outputs. Then we trained it, and the weights\n",
    "    we load here are the weights we learned then.\n",
    "    '''\n",
    "    vgg = Vgg16()\n",
    "    vgg.model.pop()\n",
    "\n",
    "    click.echo('Replacing last layer of model...')\n",
    "    for layer in vgg.model.layers: layer.trainable=False\n",
    "    vgg.model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    vgg.model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    vgg.model.load_weights(os.path.join(MODEL_PATH, 'finetune_1_ll.h5'))\n",
    "\n",
    "    return vgg\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_conv_and_fc_layers(model):\n",
    "    click.echo('Splitting convolutional and fully-connected layers...')\n",
    "    layers = model.layers\n",
    "    last_conv_idx = [index for index, layer in enumerate(layers) if type(layer) is Convolution2D][-1]   # last index of Conv layers\n",
    "\n",
    "    click.echo('Last convolutional layer is: %d' % last_conv_idx)\n",
    "\n",
    "    conv_layers = layers[:last_conv_idx + 1]  # conv layers only; i.e. first N layers until the index.\n",
    "    conv_model = Sequential(conv_layers)\n",
    "    fc_layers = layers[last_conv_idx + 1:] # remaining layers are Dense or fully-connected (FC)\n",
    "\n",
    "    return conv_model, conv_layers, fc_layers\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def precalculate_conv_output(model, train_batches, valid_batches):\n",
    "    click.echo('Precalculating convolutional layer outputs...')\n",
    "    train_features = model.predict_generator(train_batches, train_batches.nb_sample)\n",
    "    click.echo('train_features shape: %s' % (train_features.shape,))\n",
    "\n",
    "    valid_features = model.predict_generator(valid_batches, valid_batches.nb_sample)\n",
    "    click.echo('valid_features shape: %s' % (valid_features.shape,))\n",
    "\n",
    "    click.echo('Saving data...')\n",
    "    utils.save_array(os.path.join(MODEL_PATH, 'train_convlayer_features.bc'), train_features)\n",
    "    utils.save_array(os.path.join(MODEL_PATH, 'valid_convlayer_features.bc'), valid_features)\n",
    "\n",
    "    return train_features, valid_features\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data():\n",
    "    click.echo('Re-creating image data generators with data augmentation...')\n",
    "    gen = image.ImageDataGenerator(rotation_range=15, width_shift_range=0.1,\n",
    "                                   height_shift_range=0.1, zoom_range=0.1, horizontal_flip=True)\n",
    "    train_batches = utils.get_batches(TRAIN_PATH, gen, batch_size=BATCH_SIZE)\n",
    "\n",
    "    # NB: We don't want to augment or shuffle the validation set\n",
    "    valid_batches = utils.get_batches(VALID_PATH, shuffle=False, batch_size=BATCH_SIZE)\n",
    "\n",
    "    return train_batches, valid_batches\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copy the weights from the pre-trained model.\n",
    "# NB: Since we're removing dropout, we want to half the weights\n",
    "def proc_no_dropout_wgts(layer):\n",
    "    return [o / 2 for o in layer.get_weights()]\n",
    "\n",
    "\n",
    "def get_fc_model_no_dropout(opt, input_shape, fc_layers):\n",
    "    '''\n",
    "    Create a Dense model with dropout removed.\n",
    "    '''\n",
    "    click.echo('Creating Dense model with dropout removed...')\n",
    "    model = Sequential([\n",
    "        MaxPooling2D(input_shape=input_shape),\n",
    "        Flatten(),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(0.),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(0.),\n",
    "        Dense(2, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    for l1, l2 in zip(model.layers, fc_layers):\n",
    "        l1.set_weights(proc_no_dropout_wgts(l2))\n",
    "\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bn_layers(p, input_shape):\n",
    "    return [\n",
    "        MaxPooling2D(input_shape=input_shape),\n",
    "        Flatten(),\n",
    "        Dense(4096, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(4096, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(1000, activation='softmax')\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def proc_bn_wgts(layer, prev_p, new_p):\n",
    "    scal = (1-prev_p)/(1-new_p)\n",
    "    return [o*scal for o in layer.get_weights()]\n",
    "\n",
    "\n",
    "def get_fc_model_batchnorm(p, input_shape):\n",
    "    click.echo('Creating Dense model with batchnorm...')\n",
    "    bn_model = Sequential(get_bn_layers(p, input_shape))\n",
    "    load_fc_weights_from_vgg16bn(bn_model)\n",
    "    for l in bn_model.layers:\n",
    "        if type(l)==Dense: l.set_weights(proc_bn_wgts(l, 0.5, 0.6))\n",
    "\n",
    "    # Remove last layer and lock all the others\n",
    "    bn_model.pop()\n",
    "    for layer in bn_model.layers: layer.trainable=False\n",
    "\n",
    "    # Add linear layer (2-class) (just doing the ImageNet mapping to Kaggle dogs and cats)\n",
    "    bn_model.add(Dense(2,activation='softmax'))\n",
    "\n",
    "    bn_model.compile(Adam(), 'categorical_crossentropy', metrics=['accuracy'])      # NOTE: Adam optimizer\n",
    "\n",
    "    return bn_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_fc_weights_from_vgg16bn(model):\n",
    "    click.echo('Loading batchnorm weights from vgg16bn model...')\n",
    "    # See imagenet_batchnorm.ipynb for info on how the weights for\n",
    "    # Vgg16BN can be generated from the standard Vgg16 weights.\n",
    "    from vgg16bn import Vgg16BN\n",
    "    vgg16_bn = Vgg16BN()\n",
    "    _, fc_layers = utils.split_at(vgg16_bn.model, Convolution2D)\n",
    "    utils.copy_weights(fc_layers, model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_models(opt, conv_model, fc_model):\n",
    "    click.echo('Combining conv_model and fc_model...')\n",
    "    # Look how easy it is to connect two models together!\n",
    "    for layer in conv_model.layers: layer.trainable = False\n",
    "    conv_model.add(fc_model)\n",
    "    conv_model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return conv_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_final_model(opt, conv_layers, bn_model):\n",
    "    click.echo('Creating final model from conv_layers and bn_model...')\n",
    "    final_model = Sequential(conv_layers)\n",
    "    for layer in final_model.layers: layer.trainable = False\n",
    "    final_model.add(bn_model)\n",
    "    final_model.compile(optimizer=opt,\n",
    "                        loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_model(model, train_batches, valid_batches, num_epochs=NUM_EPOCHS):\n",
    "    click.echo('Fitting model...')\n",
    "    model.fit_generator(train_batches, samples_per_epoch=train_batches.n, nb_epoch=num_epochs,\n",
    "                            validation_data=valid_batches, nb_val_samples=valid_batches.n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_array(batches):\n",
    "    array = np.concatenate([batches.next() for i in range(batches.nb_sample)])\n",
    "    batches.reset()\n",
    "\n",
    "    return array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_model(model, valid_array, valid_classes, valid_labels):\n",
    "    click.echo('evaluating model with validation data...')\n",
    "    test_loss = model.evaluate(valid_array, valid_labels)\n",
    "    click.echo()\n",
    "    click.echo('test_loss: %s' % (test_loss,))\n",
    "\n",
    "    click.echo('confusion matrix...')\n",
    "    preds = model.predict_classes(valid_array, batch_size=BATCH_SIZE)\n",
    "    probs = model.predict_proba(valid_array, batch_size=BATCH_SIZE)[:, 0]\n",
    "    click.echo()\n",
    "    \n",
    "    cm = confusion_matrix(valid_classes, preds)\n",
    "    click.echo(cm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(model):\n",
    "    click.echo('Predicting labels for test data set...')\n",
    "    TEST_BATCHES = utils.get_batches(TEST_PATH, shuffle=False, batch_size=BATCH_SIZE)\n",
    "    TEST_PREDS = model.predict_generator(TEST_BATCHES, TEST_BATCHES.nb_sample)\n",
    "    TEST_FILENAMES = TEST_BATCHES.filenames\n",
    "\n",
    "    #Save our test results arrays so we can use them again later\n",
    "    # click.echo('Saving raw prediction results.')\n",
    "    # utils.save_array(os.path.join(MODEL_PATH, 'test_preds.dat'), TEST_PREDS)\n",
    "    # utils.save_array(os.path.join(MODEL_PATH, 'filenames.dat'), TEST_FILENAMES)\n",
    "\n",
    "    # Grab the dog prediction column\n",
    "    IS_DOG = TEST_PREDS[:, 1]\n",
    "\n",
    "    # To play it safe, we use a sneaky trick to round down our edge predictions\n",
    "    # Swap all ones with .95 and all zeros with .05\n",
    "    IS_DOG = IS_DOG.clip(min=0.05, max=0.95)\n",
    "\n",
    "    # Extract imageIds from the filenames in our test/unknown directory\n",
    "    IDS = np.array([int(os.path.splitext(os.path.basename(f))[0])\n",
    "                    for f in TEST_FILENAMES])\n",
    "\n",
    "    # Combine the ids and IS_DOG columns into a single 2-column array.\n",
    "    SUBMIT = np.stack([IDS, IS_DOG], axis=1)\n",
    "\n",
    "    click.echo('Formatting and saving data for Kaggle submission.')\n",
    "    np.savetxt(os.path.join(RESULTS_PATH, 'kaggle_submission.csv'), SUBMIT,\n",
    "            fmt='%d,%.5f', header='id,label', comments='')\n",
    "\n",
    "    click.echo('Model training and prediction complete.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(sample, sample_set, local):\n",
    "\n",
    "    # setup\n",
    "    global BATCH_SIZE\n",
    "    global NUM_EPOCHS\n",
    "    global INPUT_PATH\n",
    "    global OUTPUT_PATH\n",
    "\n",
    "    if local:\n",
    "        # BATCH_SIZE = 16\n",
    "        BATCH_SIZE = 8\n",
    "    else:\n",
    "        BATCH_SIZE = 64\n",
    "\n",
    "    INPUT_PATH = os.path.join('.', 'input')\n",
    "    OUTPUT_PATH = os.path.join('.', 'output')\n",
    "\n",
    "    if sample:\n",
    "        INPUT_PATH = os.path.join(INPUT_PATH, sample_set)\n",
    "        OUTPUT_PATH = os.path.join(OUTPUT_PATH, sample_set)\n",
    "\n",
    "        NUM_EPOCHS = 8\n",
    "    else:\n",
    "        NUM_EPOCHS = 10\n",
    "\n",
    "    setup_folders()\n",
    "\n",
    "    # model creation and modification\n",
    "    opt = RMSprop(lr=0.001)\n",
    "    vgg = create_model(opt)\n",
    "    conv_model, conv_layers, fc_layers = split_conv_and_fc_layers(vgg.model)\n",
    "\n",
    "    # load data and labels\n",
    "    train_batches, valid_batches, train_array, valid_array = load_data()\n",
    "    train_classes, valid_classes, train_labels, valid_labels = get_true_labels(train_batches, valid_batches)\n",
    "\n",
    "    # precalculate outputs from conv layers\n",
    "    train_features, valid_features = precalculate_conv_output(conv_model, train_batches, valid_batches)\n",
    "\n",
    "    # This is the shape we want our output to be\n",
    "    input_shape=conv_layers[-1].output_shape[1:]\n",
    "    \n",
    "    # Remove dropout from the fc layers and train.\n",
    "    opt = RMSprop(lr=0.00001, rho=0.7) # Such a finely tuned model needs to be updated very slowly!\n",
    "    fc_model = get_fc_model_no_dropout(opt, input_shape, fc_layers)\n",
    "    fc_model.fit(train_features, train_labels, nb_epoch=NUM_EPOCHS, batch_size=BATCH_SIZE, validation_data=(valid_features, valid_labels))\n",
    "\n",
    "    click.echo('Saving model weights...')\n",
    "    fc_model.save_weights(os.path.join(MODEL_PATH, 'lesson3_no_dropout.h5'))\n",
    "\n",
    "    eval_model(fc_model, valid_features, valid_classes, valid_labels)\n",
    "    \n",
    "    # Now reduce overfitting using data augmentation\n",
    "    train_batches, valid_batches = augment_data()\n",
    "    \n",
    "    combined_model = combine_models(opt, conv_model, fc_model)\n",
    "    fit_model(combined_model, train_batches, valid_batches)\n",
    "    \n",
    "    click.echo('Saving combined model weights...')\n",
    "    combined_model.save_weights(os.path.join(MODEL_PATH, 'aug1.h5'))\n",
    "    \n",
    "    #eval_model(combined_model, valid_features, valid_classes, valid_labels)\n",
    "   \n",
    "\n",
    "    \n",
    "    # Further reduce overfitting using batchnorm\n",
    "    p = 0.6\n",
    "    bn_model = get_fc_model_batchnorm(p, input_shape)\n",
    "    bn_model.fit(train_features, train_labels, nb_epoch=NUM_EPOCHS, batch_size=BATCH_SIZE / 2, validation_data=(valid_features, valid_labels))\n",
    "\n",
    "    click.echo('Saving batchnorm model weights...')\n",
    "    bn_model.save_weights(os.path.join(MODEL_PATH, 'bn1.h5'))\n",
    "\n",
    "    eval_model(bn_model, valid_features, valid_classes, valid_labels)\n",
    "    \n",
    "    # combine the models\n",
    "    final_model = create_final_model(Adam(), conv_layers, bn_model)\n",
    "    fit_model(final_model, train_batches, valid_batches, NUM_EPOCHS)\n",
    "\n",
    "    click.echo('Saving final model weights...')\n",
    "    final_model.save_weights(os.path.join(MODEL_PATH, 'final.h5'))\n",
    "\n",
    "    click.echo('Done training models.')\n",
    "    #predict(vgg.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting up folders...\n",
      "\n",
      "Input folder: .\\input\\sample\n",
      "Training data: .\\input\\sample\\train\n",
      "Validation data: .\\input\\sample\\valid\n",
      "Test data: .\\input\\sample\\test\n",
      "\n",
      "Output folder: .\\output\\sample\n",
      "Model data: .\\output\\sample\\models\n",
      "Results: .\\output\\sample\\results\n",
      "\n",
      "Replacing last layer of model...\n",
      "Splitting convolutional and fully-connected layers...\n",
      "Last convolutional layer is: 30\n",
      "Loading raw training data from .\\input\\sample\\train...\n",
      "Found 200 images belonging to 2 classes.\n",
      "Loading array from generator...\n",
      "Found 200 images belonging to 2 classes.\n",
      "\tshape: (200L, 3L, 224L, 224L)\n",
      "\n",
      "Loading raw validation data from .\\input\\sample\\valid...\n",
      "Found 50 images belonging to 2 classes.\n",
      "Loading array from generator...\n",
      "Found 50 images belonging to 2 classes.\n",
      "\tshape: (50L, 3L, 224L, 224L)\n",
      "\n",
      "Getting the true labels for every image...\n",
      "Precalculating convolutional layer outputs...\n",
      "train_features shape: (200L, 512L, 14L, 14L)\n",
      "valid_features shape: (50L, 512L, 14L, 14L)\n",
      "Saving data...\n",
      "Creating Dense model with dropout removed...\n",
      "Train on 200 samples, validate on 50 samples\n",
      "Epoch 1/8\n",
      "200/200 [==============================] - 1s - loss: 0.0837 - acc: 0.9850 - val_loss: 0.0154 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      "200/200 [==============================] - 1s - loss: 3.3401e-05 - acc: 1.0000 - val_loss: 0.0108 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      "200/200 [==============================] - 1s - loss: 2.9100e-06 - acc: 1.0000 - val_loss: 0.0150 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      "200/200 [==============================] - 1s - loss: 1.6689e-07 - acc: 1.0000 - val_loss: 0.0173 - val_acc: 0.9800\n",
      "Epoch 5/8\n",
      "200/200 [==============================] - 1s - loss: 1.2010e-07 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      "200/200 [==============================] - 1s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      "200/200 [==============================] - 1s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 1.0000\n",
      "Epoch 8/8\n",
      "200/200 [==============================] - 1s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 1.0000\n",
      "Saving model weights...\n",
      "evaluating model with validation data...\n",
      "32/50 [==================>...........] - ETA: 0s\n",
      "test_loss: [0.010630832169517816, 1.0]\n",
      "confusion matrix...\n",
      "48/50 [===========================>..] - ETA: 0s\n",
      "[[23  0]\n",
      " [ 0 27]]\n",
      "Re-creating image data generators with data augmentation...\n",
      "Found 200 images belonging to 2 classes.\n",
      "Found 50 images belonging to 2 classes.\n",
      "Combining conv_model and fc_model...\n",
      "Fitting model...\n",
      "Saving combined model weights...\n",
      "Creating Dense model with batchnorm...\n",
      "Loading batchnorm weights from vgg16bn model...\n",
      "Train on 200 samples, validate on 50 samples\n",
      "Epoch 1/8\n",
      "200/200 [==============================] - 0s - loss: 1.0314 - acc: 0.7650 - val_loss: 0.1617 - val_acc: 0.9600\n",
      "Epoch 2/8\n",
      "200/200 [==============================] - 0s - loss: 1.1334 - acc: 0.8350 - val_loss: 0.1075 - val_acc: 0.9600\n",
      "Epoch 3/8\n",
      "200/200 [==============================] - 0s - loss: 0.6226 - acc: 0.8950 - val_loss: 0.1975 - val_acc: 0.9600\n",
      "Epoch 4/8\n",
      "200/200 [==============================] - 0s - loss: 1.0908 - acc: 0.8550 - val_loss: 0.0080 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      "200/200 [==============================] - 0s - loss: 0.9805 - acc: 0.8550 - val_loss: 0.0311 - val_acc: 0.9800\n",
      "Epoch 6/8\n",
      "200/200 [==============================] - 0s - loss: 1.1028 - acc: 0.8350 - val_loss: 0.0908 - val_acc: 0.9800\n",
      "Epoch 7/8\n",
      "200/200 [==============================] - 0s - loss: 1.2214 - acc: 0.8600 - val_loss: 0.0333 - val_acc: 0.9800\n",
      "Epoch 8/8\n",
      "200/200 [==============================] - 0s - loss: 0.8052 - acc: 0.8350 - val_loss: 0.2816 - val_acc: 0.9000\n",
      "Saving batchnorm model weights...\n",
      "evaluating model with validation data...\n",
      "32/50 [==================>...........] - ETA: 0s\n",
      "test_loss: [0.28159590244293214, 0.90000000476837161]\n",
      "confusion matrix...\n",
      "48/50 [===========================>..] - ETA: 0s\n",
      "[[23  0]\n",
      " [ 5 22]]\n",
      "Creating final model from conv_layers and bn_model...\n",
      "Fitting model...\n",
      "Epoch 1/8\n",
      "200/200 [==============================] - 9s - loss: 0.9003 - acc: 0.8800 - val_loss: 7.3399e-04 - val_acc: 1.0000\n",
      "Epoch 2/8\n",
      "200/200 [==============================] - 7s - loss: 0.9686 - acc: 0.8550 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 3/8\n",
      "200/200 [==============================] - 7s - loss: 0.9906 - acc: 0.8750 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 4/8\n",
      "200/200 [==============================] - 7s - loss: 0.5766 - acc: 0.8950 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 5/8\n",
      "200/200 [==============================] - 7s - loss: 0.5130 - acc: 0.9500 - val_loss: 3.8280e-04 - val_acc: 1.0000\n",
      "Epoch 6/8\n",
      "200/200 [==============================] - 7s - loss: 0.4513 - acc: 0.9100 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 7/8\n",
      "200/200 [==============================] - 7s - loss: 0.3452 - acc: 0.9350 - val_loss: 0.0327 - val_acc: 0.9800\n",
      "Epoch 8/8\n",
      "200/200 [==============================] - 7s - loss: 0.4963 - acc: 0.9350 - val_loss: 0.0227 - val_acc: 0.9800\n",
      "Saving final model weights...\n",
      "Done training models.\n"
     ]
    }
   ],
   "source": [
    "# run it!\n",
    "main(sample=True, sample_set='sample', local=True)\n",
    "#main(sample=True, sample_set='sample-05', local=True)\n",
    "#main(sample=True, sample_set='sample-10', local=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
